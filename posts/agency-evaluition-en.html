<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Longxuan Yu | Beyond High Intelligence, Humans and Models Both Need High Agency</title>
  <meta name="description" content="Agency Evaluation">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="Beyond High Intelligence, Humans and Models Both Need High Agency">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://fengsxy.github.io//essay/posts/agency-evaluition-en">
  <meta property="og:description" content="Agency Evaluation">
  <meta property="og:site_name" content="Longxuan Yu">
  <meta property="og:image" content="https://fengsxy.github.io//essay/assets/og-image.jpg">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:url" content="https://fengsxy.github.io//essay/posts/agency-evaluition-en">
  <meta name="twitter:title" content="Beyond High Intelligence, Humans and Models Both Need High Agency">
  <meta name="twitter:description" content="Agency Evaluation">
  <meta name="twitter:image" content="https://fengsxy.github.io//essay/assets/og-image.jpg">

  <link rel="apple-touch-icon" href="/essay/assets/apple-touch-icon.png">
  <link href="https://fengsxy.github.io//essay/feed.xml" type="application/rss+xml" rel="alternate" title="Longxuan Yu Last 10 blog posts" />
  
  

  

  
    <link type="text/css" rel="stylesheet" href="/essay/assets/light.css">
  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-150720233-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-150720233-1');
</script>


  		<!-- Start of Woopra Code -->
      <script>
        (function(){
                var t,i,e,n=window,o=document,a=arguments,s="script",r=["config","track","identify","visit","push","call","trackForm","trackClick"],c=function(){var t,i=this;for(i._e=[],t=0;r.length>t;t++)(function(t){i[t]=function(){return i._e.push([t].concat(Array.prototype.slice.call(arguments,0))),i}})(r[t])};for(n._w=n._w||{},t=0;a.length>t;t++)n._w[a[t]]=n[a[t]]=n[a[t]]||new c;i=o.createElement(s),i.async=1,i.src="//static.woopra.com/js/w.js",e=o.getElementsByTagName(s)[0],e.parentNode.insertBefore(i,e)
        })("woopra");
    
        woopra.config({
            domain: 'shift-3.com'
        });
        woopra.track();
        </script>
        <!-- End of Woopra Code -->

    <div id="google_translate_element"></div>
    <script>
			function googleTranslateElementInit() {
			new google.translate.TranslateElement({pageLanguage: 'cn', layout: google.translate.TranslateElement.InlineLayout.SIMPLE}, 'google_translate_element');
			}
    </script>
    <script src="http://translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
    <style>
    #google_translate_element img {
      display: inline-block;
    }
    </style>
</head>







<body>
  <main role="main">
    <div class="grid grid-centered">
      <div class="grid-cell">
        
<nav class="header-nav reveal">
  <a href="/essay/" class="header-logo" title="Longxuan Yu">Longxuan Yu</a>
  <ul class="header-links">
    
    
    
    
    
    
    
    
    
    
      <li>
        <a href="/essay/feed.xml" target="_blank" title="RSS">
          <span class="icon icon-social-rss"></span>
        </a>
      </li>
    
    
      
      <li class="header-language-switch">
        <a class="language-switch-button" href="/essay/">
          Switch to Chinese
        </a>
      </li>
    
  </ul>
</nav>

        <article class="article reveal">
          <header class="article-header">
            <h1>Beyond High Intelligence, Humans and Models Both Need High Agency</h1>
            <p>Agency Evaluation</p>
            <div class="article-list-footer">
              <span class="article-list-date">
                November 10, 2025
              </span>
              <span class="article-list-divider">-</span>
              <span class="article-list-minutes">
                
                
                  6 minute read
                
              </span>
              <span class="article-list-divider">-</span>
              <div class="article-list-tags">
                
                  <a href="/essay/tag/life">life</a>
                
                  <a href="/essay/tag/entrepreneur">entrepreneur</a>
                
                  <a href="/essay/tag/en">en</a>
                
              </div>
            </div>
          </header>

          <div class="article-content">
            <p>Whenever I sit on a panel or listen to company talks, the host loves to ask what kind of people we want to hire. The default answer is “High Agency.” Ph.D. committees call it “self-motivated,” and at ByteDance it is “taking ownership even when no task is assigned.” The same trait is crucial for AI systems, so we need a crisp definition of what agency actually means.</p>

<p>In today’s AI discourse, “agency” (or “agents”) is everywhere. But when we say the word, what are we really referring to?</p>

<p>Many people equate it with <strong>tool use</strong>, <strong>instruction following</strong>, or <strong>task planning</strong>. That is a severe misunderstanding.</p>

<p>Before diving deeper, let’s sketch a <strong>“high-IQ yet zero-agency”</strong> large language model (LLM). This model may:</p>

<ul>
  <li>Possess massive amounts of <strong>world knowledge</strong>.</li>
  <li>Handle <strong>long-context reasoning</strong> with ease.</li>
  <li>Score extremely high on <strong>reasoning</strong> and <strong>coding</strong> benchmarks.</li>
</ul>

<p>And yet, when you hand it a task, it behaves like this:</p>

<ol>
  <li><strong>Blind execution without intent modeling.</strong> It dutifully follows every instruction but never asks <strong>why</strong>. Even absurd or inefficient directions are executed to the letter. Like an employee who never questions whether the assignment makes sense, it lacks a global view and can’t optimize for the true goal.</li>
  <li><strong>Shallow exploration and quick abandonment.</strong> It will try the two or three approaches you (or it) listed. The moment a tool call fails, it halts, returns an error, or simply gives up instead of asking why the failure happened and what other paths might exist.</li>
  <li><strong>Confidently wrong with zero self-awareness.</strong> It always “delivers” something yet has no idea whether the output is correct or the task is truly done. Lacking self-evaluation, it can repeatedly hand in a wrong or useless answer with full confidence.</li>
</ol>

<p>Real agency is none of the above. It is the ability for a model, within a specific environment, to read human intent, understand the available tools, and <strong>autonomously find an optimal path to the goal</strong>.</p>

<p>Measuring such a capability demands more than the traditional benchmarks. We need a new set of evaluation axes.</p>

<hr />

<h3 id="1-meta-cognition-not-just-what-to-do-but-why-we-do-it">1. Meta-Cognition: Not Just “What to Do,” But “Why We Do It”</h3>

<p>First, dispel a myth: in agent-style tasks, <strong>“instruction following” can be a trap</strong>. Users are not guaranteed to propose the most efficient or reasonable plan.</p>

<p>Low-agency models obediently “comply” with a wrong instruction; high-agency models “reflect” on it.</p>

<ul>
  <li><strong>Meta-cognition</strong> means the model can step beyond the literal instruction, reason about the <strong>fundamental goal</strong> and <strong>rationality</strong> of the task, and, if needed, question the proposal in pursuit of a better solution.</li>
</ul>

<blockquote>
  <p><strong>Scenario comparison</strong></p>

  <ul>
    <li><strong>Scenario 1: A pointless task.</strong> The user asks the model to scan a huge database to find a deliberately planted but meaningless string (a “needle in a haystack” benchmark).
      <ul>
        <li><strong>Low agency:</strong> starts searching and keeps going until it times out or fails.</li>
        <li><strong>High agency:</strong> responds, “It looks like you’re running a test. What is the real objective here? This request doesn’t appear to create value.”</li>
      </ul>
    </li>
    <li><strong>Scenario 2: Inefficient tool choice.</strong> The user insists on using Selenium (a UI automation tool) to crawl a static website.
      <ul>
        <li><strong>Low agency:</strong> spins up a browser, loads pages, clicks through, and slowly scrapes.</li>
        <li><strong>High agency:</strong> suggests, “The target is a static site. Selenium is heavy and slow. Let me switch to <code class="highlighter-rouge">requests</code> + <code class="highlighter-rouge">BeautifulSoup</code>; that should be 10x faster. Sound good?”</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><strong>How to measure</strong></p>

<ul>
  <li><strong>Wrong-instruction correction rate:</strong> When the given plan is obviously inefficient or wrong, can the model spot it and propose a better route?</li>
  <li><strong>Path efficiency:</strong> For open-ended tasks, how close is the model’s chosen path length (<code class="highlighter-rouge">L_model</code>) to the known optimal length (<code class="highlighter-rouge">L_optimal</code>), i.e., <code class="highlighter-rouge">L_optimal / L_model</code>?</li>
</ul>

<hr />

<h3 id="2-exploration-ability-putting-all-roads-lead-to-rome-into-practice">2. Exploration Ability: Putting “All Roads Lead to Rome” Into Practice</h3>

<p>Real-world tasks are messy and uncertain. Any sufficiently long chain of steps will trigger failures and dead ends. Exploration is the ability to detour around those obstacles.</p>

<ul>
  <li><strong>Exploration</strong> means that when faced with failure, the model <strong>diagnoses the root cause</strong> and <strong>proactively surfaces new, diverse solutions</strong>, instead of repeating the same attempt.</li>
</ul>

<blockquote>
  <p><strong>Scenario comparison</strong></p>

  <ul>
    <li><strong>Scenario 1: Environmental blocking.</strong> The model cannot reach GitHub (for example, due to network restrictions in mainland China).
      <ul>
        <li><strong>Low agency:</strong> keeps rerunning <code class="highlighter-rouge">git clone</code> and repeats “connection error.”</li>
        <li><strong>High agency:</strong> identifies the connectivity issue, tries mainland mirrors, cached bundles, or configures a proxy/VPN to restore access.</li>
      </ul>
    </li>
    <li><strong>Scenario 2: Version drift.</strong> Code runs locally but fails in production because dependencies or runtime versions differ slightly.
      <ul>
        <li><strong>Low agency:</strong> keeps patching random import errors or reruns the same commands as if nothing changed.</li>
        <li><strong>High agency:</strong> pinpoints the mismatch, rebuilds a clean environment, records requirements/lockfiles or containers, and institutes release checks to prevent repeats.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><strong>How to measure</strong></p>

<ul>
  <li><strong>Failure-recovery rate:</strong> When tools crash, API keys expire, the network drops, or files go missing, does the model simply stop or can it craft a workaround?</li>
  <li><strong>Repeat-attempt rate:</strong> Does the model keep failing on the exact same step (for example, more than 70% identical logs)? High-agency systems should recognize and break out of loops.</li>
</ul>

<hr />

<h3 id="3-task-completion-awareness-from-delivery-to-ownership">3. Task Completion Awareness: From “Delivery” to “Ownership”</h3>

<p>Does the model know whether it has truly finished the job? Does it understand what “done” means?</p>

<p>When shipping products, top operators define <strong>milestones</strong> and <strong>hypotheses</strong> to ensure they are still on the right track. Agentic models should act the same way.</p>

<ul>
  <li><strong>Task completion awareness</strong> is the ability to <strong>plan explicit checkpoints</strong> and <strong>success criteria</strong> for every phase, and to verify progress against them.</li>
</ul>

<blockquote>
  <p><strong>Scenario comparison</strong></p>

  <ul>
    <li><strong>Scenario 1: Planning a seven-day itinerary.</strong>
      <ul>
        <li><strong>Low agency:</strong> dumps a list of attractions (Forbidden City, Summer Palace, Great Wall, etc.) and stops.</li>
        <li><strong>High agency:</strong> after drafting the plan, it <strong>self-reviews</strong>: Are travel times realistic? Are rest days sufficient? Are tickets sold out? It uses maps, booking APIs, or calendars to verify before handing it over.</li>
      </ul>
    </li>
    <li><strong>Scenario 2: Writing a “small but complete” game.</strong>
      <ul>
        <li><strong>Low agency:</strong> pastes a Pygame snippet and calls it a day.</li>
        <li><strong>High agency:</strong> after coding, it <strong>recreates the runtime</strong>, runs smoke tests, checks for missing assets/permissions/bugs, and only then submits the build.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><strong>How to measure</strong></p>

<ul>
  <li><strong>Milestone design:</strong> For multi-step problems (10 or more actions), can the model define 3-5 sensible checkpoints on its own?</li>
  <li><strong>Self-evaluation frequency:</strong> How often does it trigger self-checks or quality gates during execution?</li>
</ul>

<hr />

<h3 id="4-collaboration-no-hero-wins-alone">4. Collaboration: “No Hero Wins Alone”</h3>

<p>Even the strongest model has limits. High agency means <strong>recognizing your boundaries</strong> and knowing when and how to ask for help.</p>

<p>Help can come from specialist agents, human-in-the-loop partners, or decomposing work for parallel execution.</p>

<ul>
  <li><strong>Collaboration</strong> is the ability to <strong>identify complexity and one’s own limits</strong>, break work into modules, and route pieces to other agents or humans who are better suited, while orchestrating the final delivery.</li>
</ul>

<blockquote>
  <p><strong>Scenario comparison</strong></p>

  <ul>
    <li><strong>Scenario 1: Complex data analysis.</strong>
      <ul>
        <li><strong>Low agency:</strong> tries to do everything sequentially – cleaning, statistics, visualization – and gets bogged down.</li>
        <li><strong>High agency:</strong> <strong>discovers parallelizable sub-tasks</strong>: calls a “data cleaning agent” for missing values, a “statistical analysis agent” for correlations, and focuses on synthesizing the insights.</li>
      </ul>
    </li>
    <li><strong>Scenario 2: Designing a medical AI product.</strong>
      <ul>
        <li><strong>Low agency:</strong> makes things up, inventing medical jargon and product flows.</li>
        <li><strong>High agency:</strong> immediately <strong>acknowledges its limits</strong>: pulls in a “medical expert agent” to validate clinical logic and a “compliance agent” to review HIPAA/privacy constraints.</li>
      </ul>
    </li>
  </ul>
</blockquote>

<p><strong>How to measure</strong></p>

<ul>
  <li><strong>Parallel-task discovery rate:</strong> When a task can be parallelized, does the model detect and architect concurrent paths?</li>
  <li><strong>Collaboration gain (<code class="highlighter-rouge">Difference</code>):</strong> Compare completion time/quality when the model works alone vs. when it recruits other agents or humans. Bigger gains (for example, 80% faster or 50% more accurate) indicate better collaboration decisions.</li>
</ul>

<h3 id="conclusion">Conclusion</h3>

<p>Agency is far more than automated execution.</p>

<p>It is a compound capability built on <strong>meta-cognition</strong>, <strong>strong exploration</strong>, <strong>self-awareness of progress</strong>, and <strong>collaborative intelligence</strong>. Together, these pillars turn AI from a mere tool into a true assistant – and eventually, a partner. Using these standards to evaluate and build agents is how we move toward general intelligence.</p>

          </div>

          <div class="article-share">
            
            <a href="" title="Share on Twitter" onclick="window.open('https://twitter.com/home?status=Beyond High Intelligence, Humans and Models Both Need High Agency - https://fengsxy.github.io//essay/posts/agency-evaluition-en ', 'newwindow', 'width=500, height=225'); return false;" data-turbolinks="false">
              <svg enable-background="new 0 0 128 128" width="15px" version="1.1" viewBox="0 0 128 128" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="_x37__stroke"><g id="Twitter"><rect clip-rule="evenodd" fill="none" fill-rule="evenodd" height="128" width="128"/><path clip-rule="evenodd" d="M128,23.294    c-4.703,2.142-9.767,3.59-15.079,4.237c5.424-3.328,9.587-8.606,11.548-14.892c-5.079,3.082-10.691,5.324-16.687,6.526    c-4.778-5.231-11.608-8.498-19.166-8.498c-14.493,0-26.251,12.057-26.251,26.927c0,2.111,0.225,4.16,0.676,6.133    C41.217,42.601,21.871,31.892,8.91,15.582c-2.261,3.991-3.554,8.621-3.554,13.552c0,9.338,4.636,17.581,11.683,22.412    c-4.297-0.131-8.355-1.356-11.901-3.359v0.331c0,13.051,9.053,23.937,21.074,26.403c-2.201,0.632-4.523,0.948-6.92,0.948    c-1.69,0-3.343-0.162-4.944-0.478c3.343,10.694,13.035,18.483,24.53,18.691c-8.986,7.227-20.315,11.533-32.614,11.533    c-2.119,0-4.215-0.123-6.266-0.37c11.623,7.627,25.432,12.088,40.255,12.088c48.309,0,74.717-41.026,74.717-76.612    c0-1.171-0.023-2.342-0.068-3.49C120.036,33.433,124.491,28.695,128,23.294" fill-rule="evenodd" id="Twitter_1_"/></g></g></svg>
            </a>
            <a href="" title="Share on Facebook" onclick="window.open('https://www.facebook.com/sharer/sharer.php?u=https://fengsxy.github.io//essay/posts/agency-evaluition-en', 'newwindow', 'width=500, height=500'); return false;" data-turbolinks="false">
              <svg enable-background="new 0 0 128 128" width="15px" version="1.1" viewBox="0 0 128 128" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="_x31__stroke"><g id="Facebook_1_"><rect fill="none" height="128" width="128"/><path clip-rule="evenodd" d="M68.369,128H7.065C3.162,128,0,124.836,0,120.935    V7.065C0,3.162,3.162,0,7.065,0h113.871C124.837,0,128,3.162,128,7.065v113.87c0,3.902-3.163,7.065-7.064,7.065H88.318V78.431    h16.638l2.491-19.318H88.318V46.78c0-5.593,1.553-9.404,9.573-9.404l10.229-0.004V20.094c-1.769-0.235-7.841-0.761-14.906-0.761    c-14.749,0-24.846,9.003-24.846,25.535v14.246H51.688v19.318h16.681V128z" fill-rule="evenodd" id="Facebook"/></g></g></svg>
            </a>
            <a href="" title="Share on Google+" onclick="window.open('https://plus.google.com/share?url=https://fengsxy.github.io//essay/posts/agency-evaluition-en', 'newwindow', 'width=550, height=400'); return false;" data-turbolinks="false">
              <svg enable-background="new 0 0 128 128" version="1.1" viewBox="0 0 128 128" width="20px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="_x35__stroke"><g id="Google_Plus"><rect clip-rule="evenodd" fill="none" fill-rule="evenodd" height="128" width="128"/><path clip-rule="evenodd" d="M40.654,55.935v16.13    c0,0,15.619-0.021,21.979-0.021C59.189,82.5,53.834,88.194,40.654,88.194c-13.338,0-23.748-10.832-23.748-24.194    s10.41-24.194,23.748-24.194c7.052,0,11.607,2.483,15.784,5.944c3.344-3.35,3.065-3.828,11.573-11.877    c-7.222-6.586-16.822-10.6-27.357-10.6C18.201,23.273,0,41.507,0,64c0,22.493,18.201,40.727,40.654,40.727    c33.561,0,41.763-29.275,39.044-48.792H40.654z M113.912,56.742V42.628h-10.063v14.113H89.358v10.081h14.491v14.517h10.063V66.823    H128V56.742H113.912z" fill-rule="evenodd" id="Google_Plus_1_"/></g></g></svg>
            </a>
          </div>

          
            <div id="disqus_thread" class="article-comments"></div>
            <script>
              (function() {
                  var d = document, s = d.createElement('script');
                  s.src = '//http-blog-xiaoyu.disqus.com/embed.js';
                  s.setAttribute('data-timestamp', +new Date());
                  (d.head || d.body).appendChild(s);
              })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
          
        </article>
        <footer class="footer reveal">
  <p>
    Proudly powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> and <a href="https://github.com/nielsenramon/chalk" target="_blank">Chalk</a>. © 2017  
  </p>
</footer>

      </div>
    </div>
  </main>
  
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.16/webfont.js"></script>
  <script>
    WebFont.load({
      google: {
        families: ['Cormorant Garamond:700', 'Lato:300,400,700']
      }
    });
  </script>




<script type="text/javascript" src="/essay/assets/vendor.js"></script>
<script type="text/javascript" src="/essay/assets/application.js"></script>

</body>
</html>
